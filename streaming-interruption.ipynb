{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9e547f",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-3/streaming-interruption.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239464-lesson-1-streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content='Hello, Prakhar! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 13, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a788c5aef0', 'id': 'chatcmpl-CVKksx6xrktsFLpiEUKuJgFUwuLjC', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f6cc5785-63cc-4c88-9b7d-57cc02021db9-0', usage_metadata={'input_tokens': 13, 'output_tokens': 13, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Prakhar\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello again, Prakhar! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Prakhar\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Prakhar\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Prakhar\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Prakhar! How can I assist you today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Prakhar\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatOpenAI\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the Trade Tariff wars by US\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' term', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariff', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' wars', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='\"', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' generally', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' refers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' series', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' economic', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' conflicts', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' that', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' involve', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' countries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' imposing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' or', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' other', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' barriers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' each', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' other', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' retaliation', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' most', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' notable', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' recent', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' example', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' this', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' is', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' conflict', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' between', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' United', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' States', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' China', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' which', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' began', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='8', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' during', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' administration', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' President', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Donald', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Trump', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='Here', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' are', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' some', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' key', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' points', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' about', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='China', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' war', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='1', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='Initi', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='ation', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' war', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' began', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' earnest', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' March', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='8', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' when', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' announced', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' steel', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' aluminum', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' imports', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' citing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' national', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' security', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' concerns', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' This', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' was', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' followed', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' series', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' specifically', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' targeting', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Chinese', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' goods', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' justified', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' grounds', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' intellectual', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' property', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' theft', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' unfair', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' practices', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' China', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='2', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='Esc', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='al', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='ation', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' conflict', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' quickly', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' escal', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='ated', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' both', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' countries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' imposing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' multiple', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' rounds', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' each', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=\" other's\", additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' goods', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' By', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' end', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='201', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='9', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' imposed', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' over', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' $', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='360', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' billion', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' worth', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Chinese', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' goods', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' while', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' China', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' retali', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='ated', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' on', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' over', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' $', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='110', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' billion', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' worth', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' products', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='3', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='Economic', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Impact', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' led', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' increased', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' costs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' businesses', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' consumers', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' both', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' countries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Certain', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' industries', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' such', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' agriculture', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.,', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' were', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' particularly', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' hard', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' hit', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' due', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' retali', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='atory', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' from', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' China', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' uncertainty', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' also', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' affected', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' global', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' markets', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' supply', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' chains', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='4', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='Phase', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' One', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Agreement', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' January', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' ', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='202', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='0', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' China', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' signed', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' a', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='Phase', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' One', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='\"', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' deal', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Under', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' this', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' agreement', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' China', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' committed', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' increasing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' its', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' purchases', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' goods', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' services', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' by', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' at', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' least', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' $', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='200', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' billion', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' over', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' two', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' years', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' among', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' other', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' concessions', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' In', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' return', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' agreed', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' reduce', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' some', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' but', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' many', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' remained', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' place', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='5', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='O', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='ngoing', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Issues', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Despite', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Phase', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' One', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' deal', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' many', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' underlying', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' issues', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' such', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' as', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' intellectual', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' property', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' rights', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' technology', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' transfer', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' state', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' subsidies', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' remained', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' unresolved', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' COVID', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='19', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' pandemic', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' further', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' complicated', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' relations', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' economic', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' conditions', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' globally', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='6', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' **', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='B', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='iden', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Administration', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='**', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=':', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Under', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' President', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Joe', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Biden', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' maintained', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' many', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' imposed', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' during', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' Trump', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' administration', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' although', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' there', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' have', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' been', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' efforts', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' to', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' engage', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' dialogue', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' with', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' China', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' address', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' broader', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' issues', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' relationship', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='The', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' war', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' has', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' had', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' significant', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' implications', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' for', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' global', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' dynamics', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' prompting', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' discussions', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' about', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' supply', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' chain', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' resilience', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' role', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' tariffs', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' in', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' international', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' trade', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' policy', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=',', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' and', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' the', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' future', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' of', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' U', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.S', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.-', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='China', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' economic', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content=' relations', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='.', additional_kwargs={}, response_metadata={'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_65564d8ba5', 'service_tier': 'default', 'model_provider': 'openai'}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d', chunk_position='last')}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d', usage_metadata={'input_tokens': 17, 'output_tokens': 487, 'total_tokens': 504, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n",
      "{'chunk': AIMessageChunk(content='', additional_kwargs={}, response_metadata={}, id='lc_run--0efb475b-99ce-4dd8-b087-d86a06dcba8d', chunk_position='last')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the Trade Tariff wars by US\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|The| term| \"|trade| tariff| wars|\"| generally| refers| to| the| series| of| economic| conflicts| initiated| by| the| im|position| of| tariffs|,| particularly| during| the| late| |201|0|s|,| primarily| involving| the| United| States| and| several| of| its| trading| partners|.| The| most| notable| of| these| conflicts| occurred| during| the| presidency| of| Donald| Trump|,| starting| around| |201|8|.| Here|s| an| overview| of| the| key| aspects|:\n",
      "\n",
      "|1|.| **|Background| and| Initi|ation|**|:| \n",
      "|  | -| The| trade| tensions| began| when| the| Trump| administration| imposed| tariffs| on| solar| panels| and| washing| machines| in| January| |201|8|,| followed| by| steel| and| aluminum| tariffs| in| March| |201|8|.| The| administration| justified| these| tariffs| on| national| security| grounds| and| aimed| to| protect| American| industries| and| reduce| the| trade| deficit|.\n",
      "\n",
      "|2|.| **|China|**|:\n",
      "|  | -| The| most| significant| trade| conflict| was| with| China|.| The| U|.S|.| accused| China| of| unfair| trade| practices|,| including| intellectual| property| theft| and| forced| technology| transfers|.| In| response|,| the| U|.S|.| imposed| tariffs| on| billions| of| dollars|'| worth| of| Chinese| goods|,| leading| China| to| retali|ate| with| its| own| tariffs| on| American| products|.\n",
      "|  | -| This| back|-and|-f|orth| escalation| led| to| several| rounds| of| tariffs|,| affecting| a| wide| range| of| goods| and| creating| uncertainty| in| global| markets|.\n",
      "\n",
      "|3|.| **|Other| Countries|**|:\n",
      "|  | -| The| U|.S|.| also| imposed| tariffs| on| goods| from| other| countries|,| including| allies| like| the| European| Union|,| Canada|,| and| Mexico|.| These| tariffs| often| targeted| steel| and| aluminum|,| leading| to| retali|atory| measures| from| these| countries|.\n",
      "\n",
      "|4|.| **|Economic| Impact|**|:\n",
      "|  | -| The| tariff| wars| led| to| increased| costs| for| businesses| and| consumers|,| disruptions| in| supply| chains|,| and| uncertainty| in| global| markets|.| Some| industries|,| like| agriculture|,| were| particularly| hard| hit| due| to| retali|atory| tariffs| on| American| exports|.\n",
      "|  | -| The| International| Monetary| Fund| (|IM|F|)| and| other| economic| bodies| warned| that| prolonged| trade| tensions| could| slow| global| economic| growth|.\n",
      "\n",
      "|5|.| **|Resolution| Eff|orts|**|:\n",
      "|  | -| The| U|.S|.| and| China| reached| a| \"|Phase| One|\"| trade| deal| in| January| |202|0|,| which| included| commitments| from| China| to| purchase| more| American| goods| and| address| some| trade| practices|.| However|,| many| tariffs| remained| in| place|,| and| broader| issues| were| left| unresolved|.\n",
      "|  | -| With| the| change| in| U|.S|.| administration| in| |202|1|,| there| was| a| shift| in| approach|,| with| President| Joe| Biden| maintaining| some| tariffs| but| also| seeking| to| rebuild| alliances| and| address| trade| issues| through| mult|ilateral| frameworks|.\n",
      "\n",
      "|6|.| **|Long|-term| Effects|**|:\n",
      "|  | -| The| trade| wars| highlighted| vulnerabilities| in| global| supply| chains| and| led| to| discussions| about| divers|ifying| supply| sources| and| increasing| domestic| production| in| various| countries|.\n",
      "|  | -| They| also| sparked| debates| about| the| effectiveness| of| tariffs| as| a| tool| for| achieving| trade| policy| goals| and| the| need| for| reform| in| international| trade| rules|.\n",
      "\n",
      "|Overall|,| the| trade| tariff| wars| of| the| late| |201|0|s| and| early| |202|0|s| were| a| significant| chapter| in| international| trade| relations|,| with| lasting| implications| for| global| economic| policies| and| practices|.||||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the Trade Tariff wars by US\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5826e4d8-846b-4f6c-a5c1-e781d43022db",
   "metadata": {},
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "** DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "-  API: http://127.0.0.1:2024\n",
    "-  Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "-  API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "079c2ad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectError",
     "evalue": "All connection attempts failed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpx/_transports/default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpx/_transports/default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpcore/_async/connection.py:101\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpcore/_async/connection.py:78\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connect(request)\n\u001b[32m     80\u001b[39m     ssl_object = stream.get_extra_info(\u001b[33m\"\u001b[39m\u001b[33mssl_object\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpcore/_async/connection.py:124\u001b[39m, in \u001b[36mAsyncHTTPConnection._connect\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mconnect_tcp\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     stream = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_backend.connect_tcp(**kwargs)\n\u001b[32m    125\u001b[39m     trace.return_value = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpcore/_backends/auto.py:31\u001b[39m, in \u001b[36mAutoBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._init_backend()\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.connect_tcp(\n\u001b[32m     32\u001b[39m     host,\n\u001b[32m     33\u001b[39m     port,\n\u001b[32m     34\u001b[39m     timeout=timeout,\n\u001b[32m     35\u001b[39m     local_address=local_address,\n\u001b[32m     36\u001b[39m     socket_options=socket_options,\n\u001b[32m     37\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpcore/_backends/anyio.py:113\u001b[39m, in \u001b[36mAnyIOBackend.connect_tcp\u001b[39m\u001b[34m(self, host, port, timeout, local_address, socket_options)\u001b[39m\n\u001b[32m    108\u001b[39m exc_map = {\n\u001b[32m    109\u001b[39m     \u001b[38;5;167;01mTimeoutError\u001b[39;00m: ConnectTimeout,\n\u001b[32m    110\u001b[39m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[32m    111\u001b[39m     anyio.BrokenResourceError: ConnectError,\n\u001b[32m    112\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpcore/_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: All connection attempts failed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mConnectError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m client = get_client(url=URL)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Search all hosted graphs\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m assistants = \u001b[38;5;28;01mawait\u001b[39;00m client.assistants.search()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/langgraph_sdk/client.py:1124\u001b[39m, in \u001b[36mAssistantsClient.search\u001b[39m\u001b[34m(self, metadata, graph_id, limit, offset, sort_by, sort_order, select, headers, params)\u001b[39m\n\u001b[32m   1122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m select:\n\u001b[32m   1123\u001b[39m     payload[\u001b[33m\"\u001b[39m\u001b[33mselect\u001b[39m\u001b[33m\"\u001b[39m] = select\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.http.post(\n\u001b[32m   1125\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/assistants/search\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1126\u001b[39m     json=payload,\n\u001b[32m   1127\u001b[39m     headers=headers,\n\u001b[32m   1128\u001b[39m     params=params,\n\u001b[32m   1129\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/langgraph_sdk/client.py:341\u001b[39m, in \u001b[36mHttpClient.post\u001b[39m\u001b[34m(self, path, json, params, headers, on_response)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m headers:\n\u001b[32m    340\u001b[39m     request_headers.update(headers)\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m r = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.post(\n\u001b[32m    342\u001b[39m     path, headers=request_headers, content=content, params=params\n\u001b[32m    343\u001b[39m )\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_response:\n\u001b[32m    345\u001b[39m     on_response(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpx/_client.py:1859\u001b[39m, in \u001b[36mAsyncClient.post\u001b[39m\u001b[34m(self, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1838\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1839\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1840\u001b[39m     url: URL | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1852\u001b[39m     extensions: RequestExtensions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1853\u001b[39m ) -> Response:\n\u001b[32m   1854\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1855\u001b[39m \u001b[33;03m    Send a `POST` request.\u001b[39;00m\n\u001b[32m   1856\u001b[39m \n\u001b[32m   1857\u001b[39m \u001b[33;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(\n\u001b[32m   1860\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPOST\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1861\u001b[39m         url,\n\u001b[32m   1862\u001b[39m         content=content,\n\u001b[32m   1863\u001b[39m         data=data,\n\u001b[32m   1864\u001b[39m         files=files,\n\u001b[32m   1865\u001b[39m         json=json,\n\u001b[32m   1866\u001b[39m         params=params,\n\u001b[32m   1867\u001b[39m         headers=headers,\n\u001b[32m   1868\u001b[39m         cookies=cookies,\n\u001b[32m   1869\u001b[39m         auth=auth,\n\u001b[32m   1870\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1871\u001b[39m         timeout=timeout,\n\u001b[32m   1872\u001b[39m         extensions=extensions,\n\u001b[32m   1873\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpx/_client.py:1540\u001b[39m, in \u001b[36mAsyncClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1525\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m   1527\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m   1528\u001b[39m     method=method,\n\u001b[32m   1529\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1538\u001b[39m     extensions=extensions,\n\u001b[32m   1539\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send(request, auth=auth, follow_redirects=follow_redirects)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpx/_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpx/_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpx/_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpx/_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpx/_transports/default.py:393\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m    394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    160\u001b[39m     value = typ()\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/langchain-academy/lc-academy-env/lib/python3.13/site-packages/httpx/_transports/default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mConnectError\u001b[39m: All connection attempts failed"
     ]
    }
   ],
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://127.0.0.1:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ae885f8-102f-448a-9d68-8ded8d2bbd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming summary tokens for summarization_nodes:\n",
      "|In| the| conversation|,| Pr|ak|har| introduced| himself| and| in|quired| about| how| consultancy| works|.| I| provided| a| detailed| explanation| of| the| consultancy| process|,| which| includes| understanding| client| needs|,| drafting| proposals|,| conducting| research|,| developing| solutions|,| supporting| implementation|,| evaluating| outcomes|,| and| providing| follow|-up| services|.||||"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage, AIMessage\n",
    "config = {\"configurable\": {\"thread_id\": \"7\"}}\n",
    "\n",
    "# This input has 7 messages, which will trigger the `should_continue`to return \"summarize_conversation\"\n",
    "long_input = [\n",
    "    HumanMessage(content=\"Hi I'm Prakhar\"),\n",
    "    AIMessage(content=\"Hello what's up?\"),\n",
    "    HumanMessage(content=\"How does consultancy work?\"),\n",
    "    AIMessage(content=\"Just good critical analysis and conversational skills\"),\n",
    "    HumanMessage(content=\"What's my name?\"),\n",
    "    AIMessage(content=\"Prakhar\"),\n",
    "    HumanMessage(content=\"And how does consultancy work again?\"),\n",
    "]\n",
    "\n",
    "print(\"Streaming summary tokens for summarization_nodes:\")\n",
    "\n",
    "async for event in graph.astream_events({\"messages\": long_input}, config, version=\"v2\"):\n",
    "\n",
    "    \n",
    "    if (\n",
    "        event[\"event\"] == \"on_chat_model_stream\" \n",
    "        and event['metadata'].get('langgraph_node','') == \"summarize_conversation\"\n",
    "    ):\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
